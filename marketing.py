# -*- coding: utf-8 -*-
"""MARKETING.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BTvC3ZHrnDpDyDkKEQOZamqQ9VG8kGii

*   Sara Valentina Delgado
*   Luis Fernando Mejía
"""

!pip install surprise
import joblib
from ipywidgets import interact
import ipywidgets as widgets
from IPython.display import display
import sqlite3 as sql
import pandas as pd
import matplotlib.pyplot as plt
import plotly.graph_objs as go
from sklearn import neighbors
from sklearn.neighbors import NearestNeighbors
from surprise import Reader, Dataset
from surprise.model_selection import cross_validate, GridSearchCV
from surprise import KNNBasic, KNNWithMeans, KNNWithZScore, KNNBaseline, SVD
from surprise.model_selection import train_test_split

from google.colab import drive
drive.mount('/content/drive')

"""# Carga de datos"""

conn=sql.connect("/content/drive/MyDrive/Analitica3/MARKETING/db_movies")
#conn=sql.connect("/content/drive/MyDrive/Analitica /Analítica 3/Marketing/db_movies")
cur=conn.cursor()
cur.execute("select name from sqlite_master where type= 'table'") #ver tablas de un bd
cur.fetchall()

"""# Análisis exploratorio"""

##veamos la tabla movies
movies= pd.read_sql("select * from movies", conn)
movies

##veamos la tabla ratings
ratings= pd.read_sql("select * from ratings", conn)
ratings

#funcion para convertir a formato datetime la fecha
from datetime import datetime
ts = int("0") # se define el 1 de enero de 1970 a las 00:00:00 como fecha de referencia

# Date only
print(datetime.utcfromtimestamp(ts).strftime('%Y-%m-%d'))
def datefromtimestamp(timestamp):
    date = datetime.utcfromtimestamp(timestamp).strftime('%m-%d-%Y')
    return date

#se aplica la funcion
ratings["timestamp"] = ratings["timestamp"].apply(lambda x: datefromtimestamp(x))
ratings["timestamp"] = pd.to_datetime(ratings["timestamp"])

#se detecta si hay datos nulos en la columna title
pd.read_sql('select count(*) as nulos_title from movies where title is null;', conn)

#se detecta si hay datos nulos en la columna genres
pd.read_sql('select count(*) as nulos_genres from movies where genres is null;', conn)

#se detecta si hay datos nulos en la columna ratings
pd.read_sql('select count(*) as nulos_ratings from ratings where rating is null;', conn)

#se detecta si hay datos nulos en la columna
pd.read_sql('select count(*) as nulos_movieid from ratings where movieId is null;', conn)

#cantidad de registros de movies
pd.read_sql('select count(*) as tot_movies from movies', conn)

#cantidad registros de ratings
pd.read_sql('select count(*) as tot_ratings from ratings', conn)

movies.columns

ratings.columns

#10 peliculas más vistas
cont_movie= pd.read_sql('''select movies.title, count(ratings.movieId) as cont_movie from movies inner join ratings
 on movies.movieId = ratings.movieId group by ratings.movieId order by cont_movie desc limit 10; ''', conn)
cont_movie

#genero más visto
cont_gen=pd.read_sql('''select movies.genres, count(ratings.movieId) as cont_vistas from movies inner join ratings on movies.movieId =
ratings.movieId group by ratings.movieId order by cont_vistas desc limit 10;''', conn)
cont_gen

data= go.Bar( x=cont_gen.genres,y=cont_gen.cont_vistas, text=cont_gen.cont_vistas, textposition="outside")
Layout=go.Layout(title={
        'text': 'Distribución vistas por género',
        'x': 0.5},xaxis={'title':'Género'},yaxis={'title':'Vistas'})
go.Figure(data,Layout)

#frecuencia de las calificaciones
dis_rating=pd.read_sql('select ratings.rating, count(*) as conteo from ratings group by rating', conn)
dis_rating

#distribucion de calificaciones

data= go.Bar( x=dis_rating.rating,y=dis_rating.conteo, text=dis_rating.conteo, textposition="outside")
Layout=go.Layout(title={
        'text': 'Distribución calificaciones',
        'x': 0.5},xaxis={'title':'Calificación'},yaxis={'title':'Conteo'})
go.Figure(data,Layout)

#20 usuarios que más han calificado peliculas
usu_rating=pd.read_sql(''' select userId,
                         count(*) as cant_calif
                         from ratings userId group by userId
                         order by cant_calif asc limit 20;
                         ''',conn )
usu_rating

#distribucion
data= go.Bar( x=usu_rating.userId,y=usu_rating.cant_calif, text=usu_rating.cant_calif, textposition="outside")
Layout=go.Layout(title={
        'text': 'Cantidad de calificaciones por usuario',
        'x': 0.5},xaxis={'title':'Usuario'},yaxis={'title':'Cantidad calificaciones'})
go.Figure(data,Layout)

## Serie de tiempo de los meses en que más se ven peliculas
import plotly.express as px
ratings["timestamp"] = ratings["timestamp"].dt.month
retfecha= ratings.groupby(["timestamp"])[["userId"]].count().reset_index()
fig = px.line(retfecha, x='timestamp', y =['userId'], title = '<b>Vistas de películas mensuales<b>',
              color_discrete_sequence=px.colors.qualitative.G10)
fig.update_layout(
    template = 'simple_white',
    title_x = 0.5,
   legend_title = 'Usuarios',
    xaxis_title = '<b>Fecha<b>',
    yaxis_title = '<b>Cantidad de usuarios<b>',
)
fig.show()

"""# **Modelos**

## ***1. Sistema de recomendación basado en popularidad***
"""

# 10 peliculas con mejor promedio de calificacion
topmovies = pd.read_sql("""select movies.title, avg(ratings.rating) as MejorCalif
                            from movies
                            inner join ratings
                            on movies.movieId = ratings.movieId
                            group by genres
                            order by MejorCalif desc
                            limit 10;""", conn)

topmovies

#10 usuarios que más ven peliculas
num_vistas = pd.read_sql("""select userId, count(distinct movieID) as cant_vistas
                            from ratings
                            group by userId
                            order by cant_vistas desc
                            limit 10;""", conn)

num_vistas

#10 géneros con los promedios de calificaciones más altos
gencalif = pd.read_sql("""SELECT m.genres, avg(r.rating) as prom_calif
                        from movies as m
                       inner join (select movieId, avg(rating) as rating
                                   from ratings
                                   group by movieId
                                   having count(*) >= 100) as r on m.movieId = r.movieId
                       group by m.genres
                       order by prom_calif DESC
                       limit 10;""", conn)


gencalif

##Promedio de calificación por Usuario
vistasusuario = pd.read_sql("""select userId, count(distinct movieId) as cant_vistas,
                            avg(ratings.rating) as prom_calif from ratings
                            group by userId
                            having cant_vistas
                            order by prom_calif desc
                            limit 10;""", conn)
vistasusuario

#año de estreno de las peliculas con mejor promedio de calificación
estre = pd.read_sql("""select substr(title,-1, -4) as año_estreno,
                    substr(title, 1, length(title) - 7) as titulo,
                    avg(ratings.rating) as avg_rat, count(ratings.movieid) as vistas
                    from movies
                    inner join ratings on movies.movieid = ratings.movieid
                    group by año_estreno, titulo
                    having vistas >= 50
                    order by avg_rat desc
                    limit 10;""",conn)
estre

"""## ***2. Sistema de recomendación basado en contenido general***"""

moviescompleta =pd.read_sql("""select movies.movieid,title,
                            avg(ratings.rating) as avg_rat,
                            count(ratings.movieid) as vistas,
                            movies.genres from movies
                            inner join ratings
                            on movies.movieid = ratings.movieid
                            group by ratings.movieid
                            order by vistas desc;""", conn)
moviescompleta.head(10)

#limpiar títulos de películas y extraer el género principal
import re
def clean_title(title):
    return re.sub("[\(\[].*?[\)\]]", "",title)

def genre(series):
    genres = series.index[6:-2]

    text = []
    for i in genres:
        if series[i] == 1:
            text.append(i)
            break
    return ", ".join(text)

moviescompleta["title"] = moviescompleta["title"].apply(clean_title)
moviescompleta["title"].unique()

#separar los generos convirtiendo a dummies
genres_dumm = moviescompleta['genres'].str.get_dummies('|')
genres_dumm

#unir los géneros a la tabla moviescompleta y eliminar la columna original de géneros
moviescompleta_dm = moviescompleta.join(genres_dumm)
moviescompleta_dm.drop('genres', axis=1, inplace=True)
moviescompleta_dm

moviescompleta_dm.info()

# generar recomendaciones de películas similares en función de la correlación entre géneros
def recomendacion(movie_name = list(moviescompleta_dm['title'])):

    ind_movie=genres_dumm[moviescompleta_dm['title']==movie_name].index.values.astype(int)[0]   #### obtener indice de la pelicula seleccionado de lista
    similar_movies = genres_dumm.corrwith(genres_dumm.iloc[ind_movie,:],axis=1) ## correlación entre la pelicula seleccionado y todas las otras
    similar_movies = similar_movies.sort_values(ascending=False) #### ordenar correlaciones
    top_similar_movies=similar_movies.to_frame(name="correlación").iloc[0:11,] ### el 11 es número de peliculas recomendadas
    top_similar_movies['title']=moviescompleta_dm["title"] ### agregar los nombres (como tiene mismo indice no se debe cruzar)

    return top_similar_movies


print(interact(recomendacion))

"""##3.  ***Sistema de recomendación basado en contenido KNN***
*Basado en lo visto por el usuario*
"""

#"ratings" con las calificaciones de los usuarios
#"moviescompleta_dm" = películas y géneros codificados como variables binarias,
#"user_id" representa al usuario de interés.

def recomendar(user_id, num_recomendaciones=10):
    # Obtener las calificaciones del usuario seleccionado
    user_ratings = ratings[ratings['userId'] == user_id]

    # Obtener las películas calificadas por el usuario
    peliculas_calificadas = user_ratings[['movieId', 'rating']]

    # Filtrar las películas no calificadas por el usuario
    peliculas_no_calificadas = moviescompleta_dm[~moviescompleta_dm['movieId'].isin(peliculas_calificadas['movieId'])]

    # Crear un DataFrame con las características de las películas no calificadas
    peliculas_no_calificadas_features = peliculas_no_calificadas.drop(columns=['movieId', 'title'])

    # Inicializar el modelo de vecinos más cercanos
    model = NearestNeighbors(n_neighbors=num_recomendaciones, metric='cosine')
    model.fit(peliculas_no_calificadas_features)

    # Obtener las distancias y los índices de las películas recomendadas
    _, indices = model.kneighbors(peliculas_no_calificadas_features)

    # Obtener las películas recomendadas y agregar la calificación
    peliculas_recomendadas = peliculas_no_calificadas.iloc[indices[0]][['title', 'movieId']]
    peliculas_recomendadas['calificacion'] = moviescompleta['avg_rat']  # se utiliza la calificación promedio de las peliculas

    # Asignar una calificación o motivo específico para cada película recomendada
    # asignar una calificación promedio de las películas similares
    for i in range(len(peliculas_recomendadas)):
        movie_id = peliculas_recomendadas.iloc[i]['movieId']
        similar_movies = peliculas_calificadas[peliculas_calificadas['movieId'].isin(indices[0])]['rating']
        if len(similar_movies) > 0:
            calificacion_promedio = similar_movies.mean()
            peliculas_recomendadas.at[i, 'calificacion'] = calificacion_promedio

    return peliculas_recomendadas

# Ejemplo de uso
user_id = 52
recomendaciones = recomendar(user_id)

# Imprime las películas recomendadas con calificación o motivo
print("Películas recomendadas para el usuario {}: ".format(user_id))
print(recomendaciones)

"""##  **4. *Sistema de recomendación por filtro colaborativo***"""

#ratings.to_sql("ratings",conn)
conn = sql.connect("/content/drive/MyDrive/Analitica /Analítica 3/Marketing/db_movies")
cur=conn.cursor()
ratings=pd.read_sql('select * from ratings', conn)
watcher = Reader(rating_scale=(0, 10))


data   = Dataset.load_from_df(ratings[['userId','movieId','rating']], watcher)


models=[KNNBasic(),KNNWithMeans(),KNNWithZScore(),KNNBaseline()]
results = {}


for model in models:

    CV_scores = cross_validate(model, data, measures=["MAE","RMSE"], cv=5, n_jobs=-1)
    result = pd.DataFrame.from_dict(CV_scores).mean(axis=0).\
             rename({'test_mae':'MAE', 'test_rmse': 'RMSE'})
    results[str(model).split("algorithms.")[1].split("object ")[0]] = result


performance_df = pd.DataFrame.from_dict(results).T
performance_df.sort_values(by='RMSE')

param_grid = { 'sim_options' : {'name': ['msd','cosine','pearson', 'pearson_baseline'],
                               'min_support': [1,3,5,7,9],         ### Vecinos minimos necesarios para realixar la predicción  ###Agregar mas agrupaciones
                                'user_based': [False, True]}  ### Basado en usuario (True) o en el items/calificaciones (False)
             }

gridsearchKNNBasic = GridSearchCV(KNNBasic, param_grid, measures=['rmse'], \
                                      cv=2, n_jobs=2)

gridsearchKNNBasic.fit(data)


gridsearchKNNBasic.best_params["rmse"]
gridsearchKNNBasic.best_score["rmse"]
gs_model=gridsearchKNNBasic.best_estimator['rmse'] ### mejor estimador de gridsearch

################# Entrenar con todos los datos y Realizar predicciones con el modelo afinado

trainset = data.build_full_trainset() ### esta función convierte todos los datos en entrnamiento, las funciones anteriores dividen  en entrenamiento y evaluación
model=gs_model.fit(trainset) ## se reentrena sobre todos los datos posibles (sin dividir)

predset = trainset.build_anti_testset() ### crea una tabla con todos los usuarios y las peliculas que no han visto
#### en la columna de rating pone el promedio de todos los rating, en caso de que no pueda calcularlo para un item-usuario
len(predset)

predictions = gs_model.test(predset) ### función muy pesada, hace las predicciones de rating para todas las peliculas que no ha visto un usuario
### la funcion test recibe un test set constriuido con build_test method, o el que genera crosvalidate

predictions_df = pd.DataFrame(predictions) ### esta tabla se puede llevar a una base donde estarán todas las predicciones
predictions_df.shape
predictions_df.head()
predictions_df['r_ui'].unique() ### promedio de ratings
predictions_df.sort_values(by='est',ascending=False)

####### la predicción se puede hacer para un libro puntual
model.predict(uid=52, iid='2858',r_ui='') ### uid debía estar en número e isb en comillas

predictions_df

conn = sql.connect("/content/drive/MyDrive/Analitica /Analítica 3/Marketing/db_movies")
# Obtener la lista de usuarios
cursor = conn.cursor()
cursor.execute("SELECT DISTINCT userId FROM ratings")
users = sorted([str(row[0]) for row in cursor.fetchall()])

# Crear la lista desplegable de usuarios
user_dropdown = widgets.Dropdown(options=users, description='Usuario:')

# Crear el widget de texto para mostrar las recomendaciones
recommendations_text = widgets.HTML()

# Función para mostrar las recomendaciones para el usuario seleccionado
def show_recommendations(sender):
    # Obtener el ID del usuario seleccionado
    user_id = user_dropdown.value

    # Obtener las recomendaciones para el usuario
    cursor = conn.cursor()
    cursor.execute("SELECT title FROM movies WHERE movieId IN ({})".format(
        "SELECT movieId FROM ratings WHERE UserId = {} ORDER BY rating DESC LIMIT 15".format(user_id)))
    recommendations = [row[0] for row in cursor.fetchall()]

    # Crear una cadena HTML que contenga las recomendaciones
    html = "<ul>"
    for title in recommendations:
        html += "<li>{}</li>".format(title)
    html += "</ul>"

    # Actualizar el widget de texto con las recomendaciones
    recommendations_text.value = html

# Asociar la función show_recommendations a la lista desplegable de usuarios
user_dropdown.observe(show_recommendations, 'value')

# Mostrar la lista desplegable de usuarios y el las recomendaciones
display(user_dropdown)
display(recommendations_text)

conn = sql.connect("/content/drive/MyDrive/Analitica /Analítica 3/Marketing/db_movies")
c = conn.cursor()

# Seleccionar los géneros
c.execute("SELECT genres FROM movies")
genres = c.fetchall()

# Crear un conjunto de géneros únicos
unique_genres = set()
for g in genres:
    for genre in g[0].split('|'):
        unique_genres.add(genre)

# Convertir el conjunto de géneros únicos en una lista
unique_genres = list(unique_genres)

# Mostrar los géneros únicos
print("Lista de géneros disponibles:")
for i, genre in enumerate(unique_genres):
    print(f"{i+1}. {genre}")

# Seleccionar el género
genre_num = int(input("Seleccione el número correspondiente al género: "))
selected_genre = unique_genres[genre_num - 1]

# Mostrar las películas recomendadas
c.execute("""
    SELECT m.title, AVG(r.rating) AS avg_rating
    FROM movies m
    JOIN ratings r ON m.movieId = r.movieId
    WHERE m.genres LIKE ?
    GROUP BY m.movieId
    ORDER BY avg_rating DESC
    LIMIT 10
""", ('%'+selected_genre+'%',))

recommended_movies = c.fetchall()
print(f"\nLas 10 películas más recomendadas del género '{selected_genre}':")
for movie in recommended_movies:
    print(f"- {movie[0]} (rating promedio: {movie[1]:.2f})")

import pandas as pd
from surprise import Dataset, Reader
from surprise.model_selection import cross_validate, GridSearchCV
from surprise import KNNBasic, KNNWithMeans, KNNWithZScore, KNNBaseline
from surprise import accuracy

# Supongamos que ya tienes un DataFrame llamado "ratings" con las calificaciones de los usuarios.
ratings=pd.read_sql('select * from ratings where rating>0', conn)
# Crear un objeto Reader para definir la escala de calificación
reader = Reader(rating_scale=(0, 10))

# Cargar los datos en un formato compatible con Surprise
data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)

# Define los modelos que deseas probar
models = [KNNBasic(), KNNWithMeans(), KNNWithZScore(), KNNBaseline()]
results = {}

# Evalúa el rendimiento de cada modelo utilizando validación cruzada
for model in models:
    CV_scores = cross_validate(model, data, measures=["MAE", "RMSE"], cv=5, n_jobs=-1)
    result = pd.DataFrame.from_dict(CV_scores).mean(axis=0).rename({'test_mae': 'MAE', 'test_rmse': 'RMSE'})
    results[str(model).split("algorithms.")[1].split("object ")[0]] = result

# Crea un DataFrame con los resultados de rendimiento
performance_df = pd.DataFrame.from_dict(results).T
performance_df.sort_values(by='RMSE')

# Selecciona el mejor modelo basado en RMSE
param_grid = {
    'sim_options': {
        'name': ['msd', 'cosine'],
        'min_support': [5],
        'user_based': [False, True]
    }
}

gridsearchKNNWithMeans = GridSearchCV(KNNWithMeans, param_grid, measures=['rmse'], cv=2, n_jobs=2)
gridsearchKNNWithMeans.fit(data)

best_params = gridsearchKNNWithMeans.best_params["rmse"]
best_score = gridsearchKNNWithMeans.best_score["rmse"]
gs_model = gridsearchKNNWithMeans.best_estimator['rmse']
print("RMSE Best_params: ", best_params)
print("RMSE Best_score: " ,best_score)
print("RMSE gs_model: " ,gs_model)

# Entrena el modelo seleccionado con todos los datos
trainset = data.build_full_trainset()
model = gs_model.fit(trainset)

# Realiza predicciones para un usuario específico
def recommend_movies(user_id, n_recomendations=10):
    predset = trainset.build_anti_testset()
    predictions = gs_model.test(predset)

    # Filtra las películas recomendadas para el usuario específico
    user_predictions = [pred for pred in predictions if pred.uid == user_id]
    user_predictions.sort(key=lambda x: x.est, reverse=True)

    # Devuelve las mejores recomendaciones
    top_n = user_predictions[:n_recomendations]

    # Convierte las recomendaciones en un DataFrame
    recommendations_df = pd.DataFrame(top_n, columns=['userId', 'movieId', 'rating', 'est', 'details'])

    return recommendations_df

# Guardar el DataFrame "recomendaciones" en un archivo Excel
recomendaciones.to_excel('recommendations_df.xlsx', index=False)

# Ejemplo de uso: Recomendar películas para un usuario específico
user_id = 52  # aquí se puede poner el ID de cualquiera de los usuarios
recomendaciones = recommend_movies(user_id)
print(recomendaciones)

from surprise import KNNBasic
from surprise import Dataset
from surprise import Reader

# Crear un objeto Reader para definir la escala de calificación
reader = Reader(rating_scale=(0, 10))

# Cargar los datos
data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)

# Crear una instancia del modelo
model = KNNBasic()

# Entrenar el modelo
trainset = data.build_full_trainset()
model.fit(trainset)

# Realizar predicciones para todos los usuarios y películas
all_predictions = []
for user_id in trainset.all_users():
    for movie_id in trainset.all_items():
        prediction = model.predict(user_id, movie_id)
        all_predictions.append({
            'user_id': user_id,
            'movie_id': movie_id,
            'predicted_rating': prediction.est
        })

# Convierte todas las predicciones en un DataFrame
all_predictions_df = pd.DataFrame(all_predictions)
all_predictions_df
# Puedes guardar el DataFrame en un archivo CSV
#all_predictions_df.to_csv('all_predictions.csv', index=False)